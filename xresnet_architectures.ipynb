{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xresnet_architectures",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxmatical/pytorch-projects/blob/master/xresnet_architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol7lXaYdj2T9",
        "colab_type": "text"
      },
      "source": [
        "# Xresnet based architectures\n",
        "\n",
        "- xresnet\n",
        "- xres2net\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTEtXA4bjmUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGUPmQ9Oj2J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "    \n",
        "# weight initialization\n",
        "def init_cnn(m):\n",
        "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
        "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
        "    for l in m.children(): init_cnn(l)\n",
        "\n",
        "# activation function\n",
        "act_fn = nn.ReLU(inplace=True)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn6TDvBnlNxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# default conv layer\n",
        "def conv(ni, nf, kernel_size = 3, stride = 1, bias = False):\n",
        "    \"\"\"\n",
        "    ni: n of in channels\n",
        "    \n",
        "    nf: number of filters\n",
        "    \n",
        "    \"\"\"\n",
        "    return nn.Conv2d(ni, nf, kernel_size = kernel_size, stride = stride, padding = kernel_size//2, bias = bias)\n",
        "\n",
        "\n",
        "# conv + bn + act_fun\n",
        "def conv_layer(ni, nf, kernel_size=3, stride=1, zero_bn=False, act=True):\n",
        "    bn = nn.BatchNorm2d(nf)\n",
        "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
        "    layers = [conv(ni, nf, kernel_size, stride = stride), bn]\n",
        "    if act: \n",
        "        layers.append(act_fn)\n",
        "    return nn.Sequential(*layers)\n",
        "       \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYYjcl65QyvP",
        "colab_type": "text"
      },
      "source": [
        "In the Resblock, the last conv_layer is set to zero_bn \n",
        "\n",
        "This is because if zero_bn is true, the entire conv_layer is set to 0 since the bn sets the outputs to 0\n",
        "\n",
        "This lets the NN learn when a resblock is not needed, it learns to skip over the block if it doesn't contribute\n",
        "\n",
        "If it contributes, then it learns the weight of the bn so then the resblock actually has weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obQToJTioYyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# residual block\n",
        "\n",
        "def no_op(x): return x # no operations done if ni == nf\n",
        "\n",
        "\n",
        "class Resblock(nn.Module):\n",
        "    def __init__(self, expansion, ni, nh, stride = 1):\n",
        "        \"\"\"\n",
        "        nh = number of filters for the middle layers\n",
        "        \"\"\"\n",
        "        super(Resblock, self).__init__()\n",
        "        nf, ni = nh*expansion, ni*expansion\n",
        "        if expansion == 1:\n",
        "            layers = [conv_layer(ni, nh, 3, stride = stride), #either stride 1 (if res block) or stride = 2 for downsampling blocks\n",
        "                      conv_layer(nh, nf, 3, zero_bn = True, act = False)] # stride 1\n",
        "        else:\n",
        "            layers = [conv_layer(ni, nh, 1),\n",
        "                      conv_layer(nh, nh, 3, stride = stride), #either stride 1 (if res block) or stride = 2 for downsampling blocks\n",
        "                      conv_layer(nh, nf, 1, zero_bn = True, act = False)]\n",
        "            \n",
        "        self.convs = nn.Sequential(*layers)\n",
        "        \n",
        "        # if ni != nf, use a 1x1 conv to get the same channels, otherwise return x (no operations)\n",
        "        self.idconv = no_op if ni == nf else conv_layer(ni, nf, 1, act = False)\n",
        "        \n",
        "        self.pooling = no_op if stride == 1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = self.convs(x) # convs operations\n",
        "        x2 = self.idconv(self.pooling(x)) # pooling and 1x1 conv layer operations\n",
        "        out = x1+x2\n",
        "        return act_fn(out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6dUJ6oxX7aP",
        "colab_type": "text"
      },
      "source": [
        "Tests for the resblock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alsiLEwmX6um",
        "colab_type": "code",
        "outputId": "bff55735-bcf9-418c-e2de-c87ac12fc0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "expansion = 4\n",
        "\n",
        "tmp = torch.randn((16, 3*expansion, 226, 226)).to(device)\n",
        "\n",
        "a = Resblock(expansion, 3, 20).to(device)\n",
        "print(a(tmp).shape)\n",
        "bs, n_channels, H, W = a(tmp).size()\n",
        "print(H, W, H*W)\n",
        "\n",
        "a2 = Resblock(expansion, 3, 20, stride = 2).to(device)\n",
        "print(a2(tmp).shape)\n",
        "bs, n_channels, H, W = a2(tmp).size()\n",
        "print(H, W, H*W)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 80, 226, 226])\n",
            "226 226 51076\n",
            "torch.Size([16, 80, 113, 113])\n",
            "113 113 12769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTOJ5Z8iR-0F",
        "colab_type": "text"
      },
      "source": [
        "For XResNet. Replaces the 7x7 stride 2 stem with 3 3x3 convs (stride = 2 for first conv) in a row\n",
        "\n",
        "This is done beecause 3x3 convolutions are much less computationally expensive than a 7x7 (5.4 times more expensive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueOjqfgYxapy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating XResNet\n",
        "class XResNet(nn.Sequential):\n",
        "    def __init__(self, expansion, layers, ni = 3, n_classes=1000):\n",
        "        \n",
        "        \"\"\"\n",
        "        layers = list of length 4. \n",
        "        layer[i] = how many resblocks in each of the 4 chunks of the network\n",
        "        expansion = what value to multiply the intermediate n_out of the convlayer by\n",
        "        \"\"\"\n",
        "        #stem\n",
        "        stem = []\n",
        "        stem_sizes = [ni, 32, 32, 64]\n",
        "        for i in range(3):\n",
        "            stem.append(conv_layer(stem_sizes[i], stem_sizes[i+1], stride = 2 if i==0 else 1))\n",
        "            \n",
        "        # creating the resblock layers\n",
        "        block_sizes = [64//expansion, 64, 128, 256, 512]\n",
        "\n",
        "        \n",
        "        blocks = [self._make_layer(expansion, ni = block_sizes[i], nf = block_sizes[i+1], blocks = l, stride = 1 if i == 0 else 2) #1st stage has no downsampling\n",
        "                    for i, l in enumerate(layers)] #l in enumerate(layers) goes through layers in XResNet and sets the value of blocks based on layer[i]\n",
        "        \n",
        "        # creating network\n",
        "        super().__init__(*stem,\n",
        "                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "                      *blocks,\n",
        "                      nn.AdaptiveAvgPool2d(1), \n",
        "                      Flatten(),\n",
        "                      nn.Linear(block_sizes[-1]*expansion, n_classes)\n",
        "        )\n",
        "        \n",
        "        init_cnn(self)\n",
        "        \n",
        "    def _make_layer(self, expansion, ni, nf, blocks, stride):\n",
        "        \"\"\"\n",
        "        blocks = int. -> number of blocks to create = layer[i]\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            *[Resblock(expansion, ni if i == 0 else nf, nf, stride if i==0 else 1) # only stride 2 for the downsampling block(first block) and stride = 1 for residual blocks\n",
        "              for i in range(blocks)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yDf8BNukFoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xresnet_18 = XResNet(expansion = 1, layers = [2, 2, 2, 2])\n",
        "xresnet_34 = XResNet(expansion = 1, layers = [3, 4, 6, 3])\n",
        "xresnet_50 = XResNet(expansion = 4, layers = [3, 4, 6, 3])\n",
        "xresnet_101 = XResNet(expansion = 4, layers = [3,4,23,3])\n",
        "xresnet_152 = XResNet(expansion = 4, layers = [3,8,36,3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rytHOsqPztdy",
        "colab_type": "text"
      },
      "source": [
        "Tests for xresnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP7iJKRLzWe3",
        "colab_type": "code",
        "outputId": "e72c5437-4d64-4e67-db06-df179d47d66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "tmp = torch.randn((16, 3, 226, 226)).to(device)\n",
        "a = xresnet_50.to(device)\n",
        "print(a(tmp).shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COfY7ao1X_Vd",
        "colab_type": "text"
      },
      "source": [
        "# XRes2Net\n",
        "\n",
        "https://github.com/gasvn/Res2Net \n",
        "\n",
        "\n",
        "https://github.com/lessw2020/res2net-plus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG-gHKz6YEIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# res2 block\n",
        "\n",
        "def no_op(x): return x # no operations done if ni == nf\n",
        "\n",
        "    \n",
        "class Res2block(nn.Module):\n",
        "    def __init__(self, expansion, ni, nh, stride = 1, base_width = 26, scale = 4, first_block = False):\n",
        "        \"\"\"\n",
        "        ni: number of in channels\n",
        "        nh: number of hidden channels\n",
        "        base_width: basic width of conv3x3\n",
        "        scale: scaling ratio for the convs\n",
        "        first_block: whether the block is the first to be placed in the conv layer\n",
        "        \n",
        "        \"\"\"\n",
        "        super(Res2block, self).__init__()\n",
        "        \n",
        "        self.first_block = first_block\n",
        "        self.scale = scale\n",
        "        \n",
        "        nf, ni = nh*expansion, ni*expansion\n",
        "        \n",
        "        width = int(math.floor(nf*(base_width/64.)))\n",
        "#         print(width)\n",
        "        \n",
        "        self.conv1 = conv_layer(ni, width*scale, 1, stride = stride)\n",
        "#         print(ni, width*scale)\n",
        "        \n",
        "        \n",
        "        self.conv3 = conv_layer(width*scale, nh*expansion, kernel_size=1, act = False) # no act_fn\n",
        "        \n",
        "        n_branches = max(2, scale) - 1\n",
        "        \n",
        "        if self.first_block:\n",
        "            self.pool = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)\n",
        "            \n",
        "#         self.convs = nn.ModuleList([conv_layer(width, width, 3, stride = stride) for _ in range(n_branches)]) # should it be stride = 1 here?\n",
        "        self.convs = nn.ModuleList([conv_layer(width, width, 3, stride = 1) for _ in range(n_branches)]) \n",
        "\n",
        "        \n",
        "        # if ni != nf, use a 1x1 conv to get the same channels, otherwise return x (no operations)\n",
        "        self.idconv = no_op if ni == nf else conv_layer(ni, nf, 1, act = False)\n",
        "        \n",
        "        self.pooling = no_op if stride == 1 else nn.AvgPool2d(2, ceil_mode=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x) #conv2d 1x1 -> bn -> act_fn\n",
        "        \n",
        "#         print('x1', x1.shape)\n",
        "        # splitting into self.scale equal sized chunks\n",
        "        xs = torch.chunk(x1, self.scale, dim = 1)\n",
        "        #initialize output tensor for concatenation later on\n",
        "        y = 0\n",
        "        for idx, conv in enumerate(self.convs):\n",
        "#             print(self.pooling(xs[idx]).shape)\n",
        "#             xs[idx] = self.pooling(xs[idx])\n",
        "#               temp = self.pooling(xs[idx])\n",
        "\n",
        "            if self.first_block:\n",
        "                y = xs[idx]\n",
        "                \n",
        "                \"\"\"\n",
        "                Something needs to be fixed here for when stride != 1\n",
        "                \n",
        "                \"\"\"\n",
        "            else:\n",
        "\n",
        "#                 print('idx', idx, 'xs[idx].shape', xs[idx].shape)\n",
        "#                 if idx > 0:\n",
        "#                     print('idx', idx, 'y shape', y.shape)\n",
        "#                 else:\n",
        "#                     print('idx', idx, 'y', y)\n",
        "#                 y +=  self.idconv(self.pooling(xs[idx])) # add the residual for the 2nd and onwards chunks\n",
        "#                 print('pooled x[idx]', self.pooling(xs[idx]).shape)\n",
        "\n",
        "#                 y +=  self.pooling(xs[idx])\n",
        "\n",
        "                y += xs[idx]\n",
        "\n",
        "            y = conv(y)\n",
        "#             print('y after conv shape', y.shape)\n",
        "            x1 = torch.cat((x1, y), 1) if idx >0 else y # concat outputs, but not the 1st chunk\n",
        "\n",
        "\n",
        "        if self.scale > 1:\n",
        "            if self.first_block:\n",
        "                x1 = torch.cat((x1, self.pool(xs[len(self.convs)])), 1) #concat all the outputs together\n",
        "            else:\n",
        "                x1 = torch.cat((x1, xs[len(self.convs)]),1)\n",
        "                \n",
        "\n",
        "        x1 = self.conv3(x1) # conv1x1 -> bn -> no act_fn\n",
        "        \n",
        "        # computing the residual, changing nf or dimensions if not matching x1\n",
        "        x2 = self.idconv(self.pooling(x))\n",
        "        \n",
        "        out = x1+x2\n",
        "        \n",
        "        return out\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeK1lNaNYGIJ",
        "colab_type": "text"
      },
      "source": [
        "Tests for res2block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggTTdPV0YKRS",
        "colab_type": "code",
        "outputId": "9d07f8b1-7cb6-4304-c430-02aeec146118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "expansion = 4\n",
        "\n",
        "\n",
        "tmp = torch.randn((16, 3*expansion, 226, 226)).to(device)\n",
        "\n",
        "\n",
        "# a = Res2block(expansion, 3, 32).to(device)\n",
        "# print('output shape',a(tmp).shape)\n",
        "\n",
        "\n",
        "# bs, n_channels, H, W = a(tmp).size()\n",
        "# print(H, W, H*W)\n",
        "\n",
        "\n",
        "a2 = Res2block(expansion, 3, 20, stride = 2, first_block = False).to(device)\n",
        "print(a2(tmp).shape)\n",
        "\n",
        "# bs, n_channels, H, W = a2(tmp).size()\n",
        "# print(H, W, H*W)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 80, 113, 113])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_GiEaBaxE92a"
      },
      "source": [
        "For XRes2Net. Replace ResBlocks with Res2Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X38ej7GNE92m",
        "colab": {}
      },
      "source": [
        "# creating XResNet\n",
        "class XRes2Net(nn.Sequential):\n",
        "    def __init__(self, expansion, layers, ni = 3, n_classes=1000, base_width = 26, scale = 4):\n",
        "        \n",
        "        \"\"\"\n",
        "        layers = list of length 4. \n",
        "        layer[i] = how many resblocks in each of the 4 chunks of the network\n",
        "        expansion = what value to multiply the intermediate n_out of the convlayer by\n",
        "        \"\"\"\n",
        "        \n",
        "        self.inplanes = 64\n",
        "        \n",
        "        #stem\n",
        "        stem = []\n",
        "        stem_sizes = [ni, 32, 32, 64]\n",
        "        for i in range(3):\n",
        "            stem.append(conv_layer(stem_sizes[i], stem_sizes[i+1], stride = 2 if i==0 else 1))\n",
        "            \n",
        "        # creating the resblock layers\n",
        "        block_sizes = [64//expansion, 64, 128, 256, 512]\n",
        "        is_first_block = [True, False, False, False]\n",
        "            \n",
        "        blocks = [self._make_layer(expansion, ni = block_sizes[i], nf = block_sizes[i+1], blocks = l, stride = 1 if i == 0 else 2, first_block = is_first_block[i]) #1st stage has no downsampling\n",
        "                    for i, l in enumerate(layers)] #l in enumerate(layers) goes through layers in XResNet and sets the value of blocks based on layer[i]\n",
        "        \n",
        "        # creating network\n",
        "        super().__init__(*stem,\n",
        "                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "                      *blocks,\n",
        "                      nn.AdaptiveAvgPool2d(1), \n",
        "                      Flatten(),\n",
        "                      nn.Linear(block_sizes[-1]*expansion, n_classes)\n",
        "        )\n",
        "        \n",
        "        init_cnn(self)\n",
        "        \n",
        "    def _make_layer(self, expansion, ni, nf, blocks, stride, first_block):\n",
        "        \"\"\"\n",
        "        blocks (int): number of blocks to create = layer[i]\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            *[Res2block(expansion, ni if i == 0 else nf, nf, stride if i==0 else 1, base_width = 26, scale = 4, first_block = first_block) # only stride 2 for the downsampling block(first block) and stride = 1 for residual blocks\n",
        "              for i in range(blocks)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQQbHfllHix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xres2net_50 = XRes2Net(expansion = 4, layers = [3, 4, 6, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d1XX0vty3MB",
        "colab_type": "code",
        "outputId": "7c17b0eb-eb51-4d9c-ab56-b0bb37410d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tmp = torch.randn((16, 3, 226, 226)).to(device)\n",
        "a = xres2net_50.to(device)\n",
        "print(a(tmp).shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1 torch.Size([16, 416, 57, 57])\n",
            "here\n",
            "here\n",
            "here\n",
            "x1 torch.Size([16, 416, 57, 57])\n",
            "here\n",
            "here\n",
            "here\n",
            "x1 torch.Size([16, 416, 57, 57])\n",
            "here\n",
            "here\n",
            "here\n",
            "x1 torch.Size([16, 832, 29, 29])\n",
            "idx 0 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 1 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 2 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "x1 torch.Size([16, 832, 29, 29])\n",
            "idx 0 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 1 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 2 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "x1 torch.Size([16, 832, 29, 29])\n",
            "idx 0 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 1 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 2 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "x1 torch.Size([16, 832, 29, 29])\n",
            "idx 0 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 1 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 208, 29, 29])\n",
            "idx 2 y shape torch.Size([16, 208, 29, 29])\n",
            "here\n",
            "x1 torch.Size([16, 1664, 15, 15])\n",
            "idx 0 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 1 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 2 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "x1 torch.Size([16, 1664, 15, 15])\n",
            "idx 0 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 1 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 2 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "x1 torch.Size([16, 1664, 15, 15])\n",
            "idx 0 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 1 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 2 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "x1 torch.Size([16, 1664, 15, 15])\n",
            "idx 0 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 1 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 2 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "x1 torch.Size([16, 1664, 15, 15])\n",
            "idx 0 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 1 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 2 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "x1 torch.Size([16, 1664, 15, 15])\n",
            "idx 0 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 1 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 416, 15, 15])\n",
            "idx 2 y shape torch.Size([16, 416, 15, 15])\n",
            "here\n",
            "x1 torch.Size([16, 3328, 8, 8])\n",
            "idx 0 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 1 y shape torch.Size([16, 832, 8, 8])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 2 y shape torch.Size([16, 832, 8, 8])\n",
            "here\n",
            "x1 torch.Size([16, 3328, 8, 8])\n",
            "idx 0 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 1 y shape torch.Size([16, 832, 8, 8])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 2 y shape torch.Size([16, 832, 8, 8])\n",
            "here\n",
            "x1 torch.Size([16, 3328, 8, 8])\n",
            "idx 0 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 0 y 0\n",
            "here\n",
            "idx 1 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 1 y shape torch.Size([16, 832, 8, 8])\n",
            "here\n",
            "idx 2 xs[idx].shape torch.Size([16, 832, 8, 8])\n",
            "idx 2 y shape torch.Size([16, 832, 8, 8])\n",
            "here\n",
            "torch.Size([16, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghxvgtcyffFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}