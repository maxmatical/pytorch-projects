{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory\n",
    "\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and preprocessing MNIST\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "# MNIST dataset\n",
    "mnist = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                   train=True,\n",
    "                                   transform=transform,\n",
    "                                   download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                          batch_size=32, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST is 28x28 = 784 pixels\n",
    "\n",
    "#Discriminator\n",
    "D = nn.Sequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        nn.Linear(256, 1),\n",
    "        nn.Sigmoid())\n",
    "# Generator\n",
    "G = nn.Sequential(\n",
    "        nn.Linear(64, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(256, 784),\n",
    "        nn.Tanh())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "d_opt = torch.optim.Adam(D.parameters(), lr = 0.0002)\n",
    "g_opt = torch.optim.Adam(G.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denorm for plotting\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1000/1875], d_loss: 0.9252, g_loss: 1.5333, D(x): 0.69, D(G(z)): 0.36\n",
      "Epoch [2/20], Step [1000/1875], d_loss: 1.0656, g_loss: 1.1845, D(x): 0.61, D(G(z)): 0.37\n",
      "Epoch [3/20], Step [1000/1875], d_loss: 1.2036, g_loss: 1.6312, D(x): 0.62, D(G(z)): 0.39\n",
      "Epoch [4/20], Step [1000/1875], d_loss: 0.7774, g_loss: 1.4891, D(x): 0.71, D(G(z)): 0.28\n",
      "Epoch [5/20], Step [1000/1875], d_loss: 0.9766, g_loss: 1.2439, D(x): 0.65, D(G(z)): 0.31\n",
      "Epoch [6/20], Step [1000/1875], d_loss: 1.0137, g_loss: 1.5641, D(x): 0.68, D(G(z)): 0.37\n",
      "Epoch [7/20], Step [1000/1875], d_loss: 1.2967, g_loss: 1.3159, D(x): 0.66, D(G(z)): 0.44\n",
      "Epoch [8/20], Step [1000/1875], d_loss: 0.9878, g_loss: 1.2165, D(x): 0.60, D(G(z)): 0.29\n",
      "Epoch [9/20], Step [1000/1875], d_loss: 0.8312, g_loss: 1.1466, D(x): 0.75, D(G(z)): 0.35\n",
      "Epoch [10/20], Step [1000/1875], d_loss: 0.8462, g_loss: 1.3450, D(x): 0.65, D(G(z)): 0.24\n",
      "Epoch [11/20], Step [1000/1875], d_loss: 1.0895, g_loss: 1.4595, D(x): 0.66, D(G(z)): 0.36\n",
      "Epoch [12/20], Step [1000/1875], d_loss: 0.9391, g_loss: 2.1847, D(x): 0.60, D(G(z)): 0.22\n",
      "Epoch [13/20], Step [1000/1875], d_loss: 0.8362, g_loss: 1.3986, D(x): 0.78, D(G(z)): 0.39\n",
      "Epoch [14/20], Step [1000/1875], d_loss: 1.0525, g_loss: 1.1582, D(x): 0.63, D(G(z)): 0.30\n",
      "Epoch [15/20], Step [1000/1875], d_loss: 0.7254, g_loss: 1.2824, D(x): 0.72, D(G(z)): 0.27\n",
      "Epoch [16/20], Step [1000/1875], d_loss: 0.9860, g_loss: 1.3463, D(x): 0.61, D(G(z)): 0.29\n",
      "Epoch [17/20], Step [1000/1875], d_loss: 0.9665, g_loss: 1.4029, D(x): 0.66, D(G(z)): 0.32\n",
      "Epoch [18/20], Step [1000/1875], d_loss: 0.8586, g_loss: 1.6841, D(x): 0.66, D(G(z)): 0.28\n",
      "Epoch [19/20], Step [1000/1875], d_loss: 1.0206, g_loss: 1.3482, D(x): 0.72, D(G(z)): 0.43\n",
      "Epoch [20/20], Step [1000/1875], d_loss: 0.9551, g_loss: 1.0134, D(x): 0.69, D(G(z)): 0.36\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "n_epochs = 20\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.view(images.size(0), -1) # flatten images for MLP\n",
    "        \n",
    "        #create labels (1 for real img, 0 for fake img)\n",
    "        real_labels = torch.ones(32, 1) # batchsize = 32\n",
    "        fake_labels = torch.zeros(32, 1)\n",
    "\n",
    "        \n",
    "        \n",
    "        ########################\n",
    "        # training discrimiator\n",
    "        ########################\n",
    "        \n",
    "        # zeroing gradients\n",
    "        d_opt.zero_grad()\n",
    "        \n",
    "        # loss for real images\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # loss for fake images\n",
    "        z = torch.randn(32, 64)\n",
    "        fake_img = G(z)\n",
    "        outputs = D(fake_img)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # total loss\n",
    "        total_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        total_loss.backward()\n",
    "        d_opt.step()\n",
    "        \n",
    "        ########################\n",
    "        # training generator\n",
    "        ########################\n",
    "        # zeroing gradients\n",
    "        g_opt.zero_grad()\n",
    "        \n",
    "        # generating fake imgs \n",
    "        # batch size = 32, input size is 64\n",
    "        z = torch.randn(32, 64)\n",
    "        fake_img = G(z)\n",
    "        outputs = D(fake_img)\n",
    "        \n",
    "        # loss for generator\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch+1, n_epochs, i+1, total_step, total_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "\n",
    "\n",
    "# # Save the model checkpoints \n",
    "# #torch.save(G.state_dict(), 'G.ckpt')\n",
    "# #torch.save(D.state_dict(), 'D.ckpt')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained for 100 epochs total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting imgs \n",
    "fake_img = fake_img.reshape(fake_img.size(0), 1, 28, 28)\n",
    "save_image(denorm(fake_img), os.path.join(sample_dir, 'fake_images-100.png'.format(epoch+1))) # change epoch number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
