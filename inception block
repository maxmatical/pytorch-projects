# inception style module
class convnet(nn.Module):
    def __init__(self):
        super(convnet, self).__init__()
        self.conv_3 = nn.Sequential(
            nn.Conv2d(3, 8, 1, padding = 0),
            nn.ReLU(),
            nn.Conv2d(8, 8, 3, padding = 1),
            nn.ReLU()
        )
        self.conv_5 = nn.Sequential(
            nn.Conv2d(3, 8, 1, padding = 0),
            nn.ReLU(),
            nn.Conv2d(8, 8, 5, padding = 2),
            nn.ReLU()
        )
        self.max_pool_conv_1 = nn.Sequential(
            nn.MaxPool2d(3, stride = 3), # window size 3x3
            nn.Conv2d(3, 8, 1, padding = 0),
            nn.ReLU()
        )
        self.conv_1 = nn.Sequential(
            nn.Conv2d(3, 8, 1, padding = 0),
            nn.ReLU()
        )
        self.fc1 = nn.Linear(512, 32) # 8*5*5 is flattened 8 filters and 5x5 kernel size
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(32, 10)
        
    def forward(self, x):
        x1 = self.conv_1(x)
        x2 = self.conv_3(x)
        x3 = self.conv_5(x)
        x4 = self.max_pool_conv_1(x)
        x = torch.cat([x1,x2,x3,x4], 1) # concatenate all layers
        x = x.view(x.size(0), -1) # flatten
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
        
net = convnet()
